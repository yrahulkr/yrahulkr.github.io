---
layout: post
title: CGC - a datalog prototype for the Separate Compilation Assumption
date:   2012-03-25 17:21:00
permalink: /cgc
group: research
weight: 4
---

`cgc`  is a prototype tool that generates a sound call graph for the application part of a program without analyzing
the code of the library. It uses a context-insensitive pointer analysis to create the call graph on-the-fly.
Although the prototype is implemented in `Datalog` for ease of modification and experimentation, it could be
transcribed into Java to be embedded into an analysis framework such as
<a href="http://www.sable.mcgill.ca/soot/" target="_blank">Soot</a> or
<a href="http://wala.sourceforge.net/" target="_blank">Wala</a>.

{{ site.excerpt_separator }}

More details about `cgc`, its pointer analysis, assumptions, empirical evaluation can be found at my
<a href="{{ "/resources/pubs/conf/ecoop/AliL12.pdf" |  prepend: site.baseurl }}" target="_blank">ECOOP'12 paper</a>.

## Workflow ##
<figure>
	<img width="100%" src="{{ "/resources/images/cgc-workflow.png" |  prepend: site.baseurl }}" alt="cgc workflow" />
</figure>

## Call Graph Schema ##
`cgc` can output the generated call graph as a <a href="http://www.gupro.de/GXL/" target="_blank">GXL</a> document or a
directed <a href="http://www.graphviz.org/content/dot-language" target="_blank">DOT</a> graph file. The `DOT` graph can
be visualized using <a href="http://www.graphviz.org/" target="_blank">Graphviz</a> or converted by `cgc` to a `PNG` or a
`PS` file that can be visualized using any document previewer. The call graph `GXL` schema used by `cgc` can be found
<a href="{{ "/resources/cgc/callgraph.gxl" |  prepend: site.baseurl }}">here</a>.

## Logic Rules ##
`cgc` pointer analysis is implemented declaratively in `Datalog`. `Datalog` makes it easier to focus on "what" you want
from your analysis rather than focusing on "how" to do it. We used the context-insensitive pointer analysis from the
<a href="http://doop.program-analysis.org/" target="_blank">Doop</a> framework as our base analysis and modified it,
greatly in many cases, to fit our requirements. The logic rules for `cgc` can be found
<a href="https://www.dropbox.com/s/h448q417pw4ov76/logic.zip?dl=1">here</a>. There is a README file in the downloaded archive that explains which files are taken as is from Doop, files completely new in `cgc`, and Doop files that are
used after modifying them.

## Experiment Output ##
The output of the experiments used in the empirical evaluation found in my ECOOP'12 paper can be downloaded
<a href="https://www.dropbox.com/s/msi1tbmn3209orp/output.zip?dl=1">here</a>. The download contains two
folders, one for the <a href="http://sourceforge.net/projects/dacapobench/files/archive/2006-10-MR2/" target="_blank">DaCapo</a>
benchmarks and another one for the <a href="http://www.spec.org/jvm98/" target="_blank">SPEC JVM98</a> benchmarks.
Each benchmark program used has a folder that contains the following:

* &lt;benchmark_name&gt;.stats: a text file that contains all the output from the three tools run for each benchmark
program (`cgc`, Spark, and Doop). It contains important information like preprocessing time, analysis time, etc.
* callgraph/: a folder that contains all the call graphs generated by the three tools as well as the difference call graphs between them.
* database/: a folder that contains the LogicBlox database used by `cgc` and Doop after the analysis finishes execution.
* reflection.stats: a text file that contains statistical information about the use of reflection in the corresponding benchmark.
